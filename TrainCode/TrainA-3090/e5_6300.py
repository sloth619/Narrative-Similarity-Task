"""
Track Aè®­ç»ƒ - E5-large-v2
3090 24GB + 6300 Gemini + 1900 Synthetic
åªä¿å­˜acc > 68%çš„æ¨¡å‹
"""
import os
import gc
import torch

os.environ["CUDA_VISIBLE_DEVICES"] = "1"
os.environ["PYTORCH_ALLOC_CONF"] = "expandable_segments:True"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

from sentence_transformers import SentenceTransformer, losses, InputExample
from sentence_transformers.training_args import SentenceTransformerTrainingArguments
from sentence_transformers.trainer import SentenceTransformerTrainer
from sentence_transformers.evaluation import SentenceEvaluator
from sentence_transformers.evaluation import SimilarityFunction
from datasets import load_dataset, Dataset
import numpy as np
from sklearn.metrics import accuracy_score
from typing import Dict


# ===== è‡ªå®šä¹‰è¯„ä¼°å™¨ =====
class TrackAEvaluator:
    """Track Aè¯„ä¼°å™¨ - è¿”å›metricså­—å…¸"""

    def __init__(self, dev_data_path: str, name: str = "track_a", threshold: float = 0.69):
        self.dev_data_path = dev_data_path
        self.name = name
        self.threshold = threshold
        self.best_acc = 0.0

        # åŠ è½½éªŒè¯é›†
        self.dev_dataset = load_dataset('json', data_files=dev_data_path, split='train')
        print(f"âœ… åŠ è½½éªŒè¯é›†: {len(self.dev_dataset)} æ ·æœ¬")

    def __call__(self, model, output_path: str = None, epoch: int = -1, steps: int = -1) -> Dict[str, float]:
        """è¯„ä¼°æ¨¡å‹ - è¿”å›metricså­—å…¸"""

        predictions = []
        labels = []

        model.eval()
        device = next(model.parameters()).device

        print(f"\n{'='*60}")
        print(f"ğŸ“Š å¼€å§‹è¯„ä¼° (Epoch {epoch})...")

        with torch.no_grad():
            for item in self.dev_dataset:
                anchor = item.get('anchor_text') or item.get('anchor_story')
                text_a = item.get('text_a') or item.get('similar_story')
                text_b = item.get('text_b') or item.get('dissimilar_story')
                label = item.get('text_a_is_closer')

                if not all([anchor, text_a, text_b]) or label is None:
                    continue

                # E5éœ€è¦åŠ å‰ç¼€
                anchor = f"query: {anchor}"
                text_a = f"passage: {text_a}"
                text_b = f"passage: {text_b}"

                # ç¼–ç 
                embeddings = model.encode(
                    [anchor, text_a, text_b],
                    convert_to_tensor=True,
                    show_progress_bar=False,
                    batch_size=32,
                    device=device
                )

                # è®¡ç®—ç›¸ä¼¼åº¦
                sim_a = torch.nn.functional.cosine_similarity(
                    embeddings[0].unsqueeze(0),
                    embeddings[1].unsqueeze(0)
                ).item()

                sim_b = torch.nn.functional.cosine_similarity(
                    embeddings[0].unsqueeze(0),
                    embeddings[2].unsqueeze(0)
                ).item()

                prediction = sim_a > sim_b
                predictions.append(prediction)
                labels.append(label)

        # è®¡ç®—å‡†ç¡®ç‡
        accuracy = accuracy_score(labels, predictions)

        # æ›´æ–°æœ€ä½³
        if accuracy > self.best_acc:
            self.best_acc = accuracy

        # æ‰“å°ç»“æœ
        print(f"   å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"   é˜ˆå€¼: {self.threshold:.4f} ({self.threshold*100:.2f}%)")

        if accuracy > self.threshold:
            print(f"   âœ… è¶…è¿‡é˜ˆå€¼!")
        else:
            print(f"   âŒ æœªè¾¾é˜ˆå€¼")

        print(f"   å†å²æœ€ä½³: {self.best_acc:.4f} ({self.best_acc*100:.2f}%)")
        print(f"{'='*60}\n")

        model.train()

        # è¿”å›metricså­—å…¸ (Traineréœ€è¦)
        return {
            f"{self.name}_accuracy": accuracy,
            f"{self.name}_best_accuracy": self.best_acc
        }


# ===== æ•°æ®åŠ è½½å‡½æ•° =====
def load_training_data(data_path: str, add_prefix: bool = True):
    """åŠ è½½è®­ç»ƒæ•°æ®å¹¶æ„å»ºä¸‰å…ƒç»„"""

    dataset = load_dataset('json', data_files=data_path, split='train')

    examples = []

    for item in dataset:
        anchor = item.get('anchor_text') or item.get('anchor_story')
        text_a = item.get('text_a') or item.get('similar_story')
        text_b = item.get('text_b') or item.get('dissimilar_story')
        label = item.get('text_a_is_closer')

        if not all([anchor, text_a, text_b]):
            continue

        # ç¡®å®šæ­£è´Ÿæ ·æœ¬
        if label is not None:
            positive = text_a if label else text_b
            negative = text_b if label else text_a
        else:
            positive = text_a
            negative = text_b

        # E5éœ€è¦åŠ å‰ç¼€
        if add_prefix:
            anchor = f"query: {anchor}"
            positive = f"passage: {positive}"
            negative = f"passage: {negative}"

        # æ„å»ºInputExample (anchor, positive, negative)
        examples.append(InputExample(texts=[anchor, positive, negative]))

    return examples


# ===== ä¸»è®­ç»ƒå‡½æ•° =====
def main():
    print("="*60)
    print("ğŸš€ Track Aè®­ç»ƒ - E5-large-v2 (Trainer API)")
    print("="*60)

    # æ¸…ç†æ˜¾å­˜
    torch.cuda.empty_cache()
    gc.collect()

    # ç¡®è®¤GPU
    print(f"\nğŸ” GPUçŠ¶æ€:")
    print(f"   å¯ç”¨GPUæ•°: {torch.cuda.device_count()}")
    if torch.cuda.is_available():
        print(f"   å½“å‰GPU: cuda:{torch.cuda.current_device()}")
        print(f"   GPUåç§°: {torch.cuda.get_device_name(0)}")

    # ===== è·¯å¾„é…ç½® =====
    PROJECT_ROOT = "/home/songfeiyang/workspace/semeval"
    MODEL_PATH = "/home/songfeiyang/workspace/model/e5-large-v2"

    SYNTHETIC_DATA = f"{PROJECT_ROOT}/TrainSet/synthetic_data_for_contrastive_learning.jsonl"
    GEMINI_DATA = f"{PROJECT_ROOT}/TrainSet/gemini_generated_10k.jsonl"
    DEV_DATA = f"{PROJECT_ROOT}/TrainSet/dev_track_a.jsonl"
    OUTPUT_PATH = f"{PROJECT_ROOT}/output/track_a_e5_gemini_6k_v2"

    os.makedirs(OUTPUT_PATH, exist_ok=True)

    # ===== åŠ è½½æ¨¡å‹ =====
    print("\nğŸ“¦ åŠ è½½æ¨¡å‹...")
    model = SentenceTransformer(MODEL_PATH, device='cuda')
    print(f"   âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"   Embeddingç»´åº¦: {model.get_sentence_embedding_dimension()}")
    print(f"   å‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.0f}M")

    # ===== åŠ è½½è®­ç»ƒæ•°æ® =====
    print("\nğŸ“‚ åŠ è½½è®­ç»ƒæ•°æ®...")

    print("   1. åŠ è½½åŸå§‹Syntheticæ•°æ®...")
    synthetic_examples = load_training_data(SYNTHETIC_DATA, add_prefix=True)
    print(f"      âœ… {len(synthetic_examples):,} ä¸ªä¸‰å…ƒç»„")

    print("   2. åŠ è½½Geminiç”Ÿæˆæ•°æ®...")
    gemini_examples = load_training_data(GEMINI_DATA, add_prefix=True)
    print(f"      âœ… {len(gemini_examples):,} ä¸ªä¸‰å…ƒç»„")

    # åˆå¹¶æ•°æ®
    all_examples = synthetic_examples + gemini_examples
    print(f"\n   ğŸ“Š æ€»è®­ç»ƒæ ·æœ¬: {len(all_examples):,} ä¸ªä¸‰å…ƒç»„")

    # è½¬æ¢ä¸ºDatasetæ ¼å¼
    train_dataset = Dataset.from_dict({
        'anchor': [ex.texts[0] for ex in all_examples],
        'positive': [ex.texts[1] for ex in all_examples],
        'negative': [ex.texts[2] for ex in all_examples]
    })

    # ===== æŸå¤±å‡½æ•° =====
    train_loss = losses.MultipleNegativesRankingLoss(model=model)
    print(f"\n   æŸå¤±å‡½æ•°: MultipleNegativesRankingLoss")

    # ===== è¯„ä¼°å™¨ =====
    print("\nğŸ“Š é…ç½®è¯„ä¼°å™¨...")
    evaluator = TrackAEvaluator(
        dev_data_path=DEV_DATA,
        name="track_a",
        threshold=0.69
    )

    # ===== è®­ç»ƒé…ç½® =====
    target_lr = 3e-7
    target_warmup = 0.1
    epochs = 5
    batch_size = 16
    steps_per_epoch = len(all_examples) // batch_size

    print(f"\nâš™ï¸  è®­ç»ƒé…ç½®:")
    print(f"   æ¨¡å‹: E5-large-v2")
    print(f"   è®­ç»ƒé›†: Synthetic(1900) + Gemini(10000)")
    print(f"   æ€»æ ·æœ¬: {len(all_examples):,}")
    print(f"   Batch size: {batch_size}")
    print(f"   Learning rate: {target_lr}")
    print(f"   Warmup ratio: {target_warmup}")
    print(f"   Epochs: {epochs}")
    print(f"   Steps per epoch: {steps_per_epoch}")
    print(f"   ä¿å­˜é˜ˆå€¼: 69%")
    print(f"   è¾“å‡ºè·¯å¾„: {OUTPUT_PATH}")

    # ===== Trainerå‚æ•° =====
    args = SentenceTransformerTrainingArguments(
        output_dir=OUTPUT_PATH,
        num_train_epochs=epochs,
        per_device_train_batch_size=batch_size,
        per_device_eval_batch_size=32,
        learning_rate=target_lr,
        warmup_ratio=target_warmup,
        fp16=False,
        bf16=True,
        save_strategy="epoch",
        eval_strategy="epoch",
        logging_steps=50,
        save_total_limit=2,
        load_best_model_at_end=True,
        metric_for_best_model="track_a_accuracy",
        greater_is_better=True,
        report_to="none",
        seed=42,
    )

    # ===== åˆ›å»ºTrainer =====
    print(f"\n{'='*60}")
    print("ğŸ¯ å¼€å§‹è®­ç»ƒ...")
    print(f"{'='*60}\n")

    trainer = SentenceTransformerTrainer(
        model=model,
        args=args,
        train_dataset=train_dataset,
        loss=train_loss,
        evaluator=[evaluator],
    )

    # ===== è®­ç»ƒ =====
    try:
        trainer.train()
    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒè¢«ä¸­æ–­")

    # ===== æœ€ç»ˆè¯„ä¼° =====
    print(f"\n{'='*60}")
    print("âœ… è®­ç»ƒå®Œæˆ!")
    print(f"{'='*60}")

    print("\nğŸ” æœ€ç»ˆè¯„ä¼°...")
    final_metrics = evaluator(model, OUTPUT_PATH, epoch=-1)
    final_acc = final_metrics['track_a_accuracy']

    print(f"\nğŸ“Š æœ€ç»ˆç»“æœ:")
    print(f"   æœ€ç»ˆå‡†ç¡®ç‡: {final_acc:.4f} ({final_acc*100:.2f}%)")
    print(f"   å†å²æœ€ä½³: {evaluator.best_acc:.4f} ({evaluator.best_acc*100:.2f}%)")

    # åªåœ¨è¶…è¿‡é˜ˆå€¼æ—¶ä¿å­˜
    if final_acc > 0.69:
        print(f"\nğŸ’¾ ä¿å­˜æœ€ç»ˆæ¨¡å‹...")
        final_model_path = f"{OUTPUT_PATH}/final_model"
        model.save(final_model_path)
        print(f"   âœ… å·²ä¿å­˜åˆ°: {final_model_path}")
    else:
        print(f"\nâš ï¸  æœ€ç»ˆæ¨¡å‹æœªè¾¾é˜ˆå€¼,ä¸ä¿å­˜")

    # ===== ä¿å­˜è®­ç»ƒæ—¥å¿— =====
    log_file = f"{OUTPUT_PATH}/training_summary.txt"
    with open(log_file, 'w') as f:
        f.write(f"Training Summary\n")
        f.write(f"="*60 + "\n")
        f.write(f"Model: E5-large-v2\n")
        f.write(f"Training samples: {len(all_examples):,}\n")
        f.write(f"Epochs: {epochs}\n")
        f.write(f"Batch size: {batch_size}\n")
        f.write(f"Learning rate: {target_lr}\n")
        f.write(f"\nFinal Results:\n")
        f.write(f"Final accuracy: {final_acc:.4f} ({final_acc*100:.2f}%)\n")
        f.write(f"Best accuracy: {evaluator.best_acc:.4f} ({evaluator.best_acc*100:.2f}%)\n")
        f.write(f"Threshold: 69%\n")
        f.write(f"Model saved: {'Yes' if final_acc > 0.69 else 'No'}\n")

    print(f"\nğŸ“ è®­ç»ƒæ‘˜è¦å·²ä¿å­˜åˆ°: {log_file}")

    print(f"\n{'='*60}")
    print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆ!")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    main()