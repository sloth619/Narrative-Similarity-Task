"""
Track A é›¶æ ·æœ¬ (Zero-Shot) è¯„ä¼°è„šæœ¬ - å®Œæ•´ç‰ˆ
æ”¯æŒ: Embeddingæ¨¡å‹ + DeBERTa Multiple Choice
"""
import os
import gc
import torch
import time
import numpy as np
from sentence_transformers import SentenceTransformer, models
from datasets import load_dataset
from transformers import (
    BitsAndBytesConfig,
    DebertaV2Tokenizer,
    DebertaV2ForMultipleChoice
)
from sklearn.metrics import accuracy_score

# æ¸…ç†æ˜¾å­˜
torch.cuda.empty_cache()
gc.collect()

os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.environ["TOKENIZERS_PARALLELISM"] = "false"


# --- 1. é…ç½®åŒº ---

# ğŸ”¥ åœ¨è¿™é‡Œé€‰æ‹©æ‚¨æƒ³æµ‹è¯•çš„æ¨¡å‹
MODEL_TO_TEST = "DeBERTa-v3-large"
# MODEL_TO_TEST = "Qwen3-Embedding-4B"
# MODEL_TO_TEST = "BGE-large-en-v1.5"
# MODEL_TO_TEST = "E5-large-v2"
# MODEL_TO_TEST = "jina-embeddings-v3"

# --- 2. è·¯å¾„é…ç½® ---
PROJECT_ROOT = "/mnt/e/Code/python/Narrative-Similarity-Task"

MODEL_PATHS = {
    # Embeddingæ¨¡å‹
    "Qwen3-Embedding-4B": '/mnt/e/model/Qwen3-Embedding-4B',
    "Qwen3-Embedding-8B": '/mnt/e/model/Qwen3-Embedding-8B',
    "BGE-large-en-v1.5": '/mnt/e/model/BGE-large-en-v1.5',
    "GTE-large-en-v1.5": '/mnt/e/model/gte-large-en-v1.5',
    "E5-large-v2": '/mnt/e/model/e5-large-v2',
    "jina-embeddings-v3": '/mnt/e/model/jina-embeddings-v3',

    # Multiple Choiceæ¨¡å‹
    "DeBERTa-v3-large": "microsoft/deberta-v3-large",
    "DeBERTa-v3-base": "microsoft/deberta-v3-base",
    "RoBERTa-large": "roberta-large",
}

DEV_DATA_PATH = f'{PROJECT_ROOT}/TrainingSet1/dev_track_a.jsonl'


# --- 3. æ¨¡å‹åŠ è½½ ---

def load_embedding_model(model_name, model_path):
    """åŠ è½½Embeddingæ¨¡å‹"""
    print(f"\n{'='*60}")
    print(f"ğŸ” åŠ è½½Embeddingæ¨¡å‹: {model_name}")
    print(f"   è·¯å¾„: {model_path}")
    print(f"{'='*60}")

    start_time = time.time()

    if "Qwen" in model_name:
        print("   åº”ç”¨ 4-bit é‡åŒ–...")
        bnb_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_quant_type="nf4",
            bnb_4bit_compute_dtype=torch.bfloat16,
            bnb_4bit_use_double_quant=True,
        )

        word_embedding_model = models.Transformer(
            model_path,
            tokenizer_args={'padding_side': 'left'},
            model_args={
                "quantization_config": bnb_config,
                "device_map": "auto",
                "trust_remote_code": True
            }
        )

        embedding_dim = word_embedding_model.get_word_embedding_dimension()
        pooling_model = models.Pooling(
            word_embedding_dimension=embedding_dim,
            pooling_mode='lasttoken'
        )

        model = SentenceTransformer(
            modules=[word_embedding_model, pooling_model],
            device='cuda'
        )
    elif "jina" in model_name.lower() or "GTE" in model_name or "gte" in model_name.lower():
        model = SentenceTransformer(
            model_path,
            device='cuda',
            trust_remote_code=True
        )
    else:
        model = SentenceTransformer(model_path, device='cuda')

    end_time = time.time()
    print(f"   âœ… åŠ è½½å®Œæˆ ({end_time - start_time:.2f}ç§’)")
    return model


def load_multiple_choice_model(model_name, model_path):
    """åŠ è½½Multiple Choiceæ¨¡å‹ (DeBERTaç­‰)"""
    print(f"\n{'='*60}")
    print(f"ğŸ” åŠ è½½Multiple Choiceæ¨¡å‹: {model_name}")
    print(f"   è·¯å¾„: {model_path}")
    print(f"{'='*60}")

    start_time = time.time()

    # åŠ è½½tokenizerå’Œæ¨¡å‹
    if "DeBERTa" in model_name or "deberta" in model_name.lower():
        tokenizer = DebertaV2Tokenizer.from_pretrained(model_path)
        model = DebertaV2ForMultipleChoice.from_pretrained(model_path)
    else:
        from transformers import AutoTokenizer, AutoModelForMultipleChoice
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForMultipleChoice.from_pretrained(model_path)

    model = model.to('cuda')
    model.eval()

    end_time = time.time()
    print(f"   âœ… åŠ è½½å®Œæˆ ({end_time - start_time:.2f}ç§’)")
    print(f"   å‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.0f}M")

    return tokenizer, model


# --- 4. Embeddingæ¨¡å‹è¯„ä¼° ---

def evaluate_embedding_model(model, data_path, model_name):
    """è¯„ä¼°Embeddingæ¨¡å‹çš„é›¶æ ·æœ¬æ€§èƒ½"""
    print(f"\n{'='*60}")
    print("ğŸ“Š Embeddingæ¨¡å‹é›¶æ ·æœ¬è¯„ä¼°")
    print(f"{'='*60}")

    dataset = load_dataset('json', data_files=data_path, split='train')
    correct = 0
    total = 0

    start_time = time.time()

    for idx, item in enumerate(dataset):
        anchor = item.get('anchor_text') or item.get('anchor_story')
        text_a = item.get('text_a') or item.get('similar_story')
        text_b = item.get('text_b') or item.get('dissimilar_story')
        label = item.get('text_a_is_closer')

        if not all([anchor, text_a, text_b]) or label is None:
            continue

        try:
            embeddings = model.encode(
                [anchor, text_a, text_b],
                show_progress_bar=False,
                batch_size=32
            )

            anchor_emb = embeddings[0]
            text_a_emb = embeddings[1]
            text_b_emb = embeddings[2]

            sim_a = torch.nn.functional.cosine_similarity(
                torch.tensor(anchor_emb).unsqueeze(0),
                torch.tensor(text_a_emb).unsqueeze(0)
            ).item()

            sim_b = torch.nn.functional.cosine_similarity(
                torch.tensor(anchor_emb).unsqueeze(0),
                torch.tensor(text_b_emb).unsqueeze(0)
            ).item()

            prediction = sim_a > sim_b

            if prediction == label:
                correct += 1
            total += 1

            if (idx + 1) % 50 == 0:
                print(f"   è¿›åº¦: {idx + 1}/{len(dataset)}, å½“å‰å‡†ç¡®ç‡: {correct/total:.2%}")

        except Exception as e:
            print(f"   âš ï¸  æ ·æœ¬{idx}å¤„ç†å¤±è´¥: {e}")
            continue

    end_time = time.time()
    accuracy = correct / total if total > 0 else 0

    print(f"\n{'='*60}")
    print("âœ… è¯„ä¼°å®Œæˆ!")
    print(f"   æ¨¡å‹: {model_name}")
    print(f"   å‡†ç¡®ç‡: {accuracy:.4f} ({correct}/{total})")
    print(f"   è€—æ—¶: {end_time - start_time:.2f}ç§’")
    print(f"{'='*60}")

    return accuracy


# --- 5. Multiple Choiceæ¨¡å‹è¯„ä¼° ---

def evaluate_multiple_choice_model(tokenizer, model, data_path, model_name):
    """è¯„ä¼°Multiple Choiceæ¨¡å‹çš„é›¶æ ·æœ¬æ€§èƒ½"""
    print(f"\n{'='*60}")
    print("ğŸ“Š Multiple Choiceæ¨¡å‹é›¶æ ·æœ¬è¯„ä¼°")
    print(f"{'='*60}")

    dataset = load_dataset('json', data_files=data_path, split='train')
    predictions = []
    labels = []

    start_time = time.time()

    with torch.no_grad():
        for idx, item in enumerate(dataset):
            anchor = item.get('anchor_text') or item.get('anchor_story')
            text_a = item.get('text_a') or item.get('similar_story')
            text_b = item.get('text_b') or item.get('dissimilar_story')
            label = item.get('text_a_is_closer')

            if not all([anchor, text_a, text_b]) or label is None:
                continue

            try:
                # Tokenizeä¸¤ä¸ªé€‰æ‹©
                inputs = tokenizer(
                    [anchor, anchor],  # ä¸¤æ¬¡anchor
                    [text_a, text_b],  # ä¸¤ä¸ªé€‰é¡¹
                    truncation=True,
                    max_length=512,
                    padding='max_length',
                    return_tensors='pt'
                )

                # ç§»åˆ°GPU
                inputs = {k: v.unsqueeze(0).to('cuda') for k, v in inputs.items()}

                # æ¨ç†
                outputs = model(**inputs)
                logits = outputs.logits  # [1, 2]

                # é¢„æµ‹ (0=A, 1=B)
                pred = torch.argmax(logits, dim=-1).item()
                pred_bool = (pred == 0)  # True if A, False if B

                predictions.append(pred_bool)
                labels.append(label)

                if (idx + 1) % 50 == 0:
                    acc = accuracy_score(labels, predictions)
                    print(f"   è¿›åº¦: {idx + 1}/{len(dataset)}, å½“å‰å‡†ç¡®ç‡: {acc:.2%}")

            except Exception as e:
                print(f"   âš ï¸  æ ·æœ¬{idx}å¤„ç†å¤±è´¥: {e}")
                continue

    end_time = time.time()
    accuracy = accuracy_score(labels, predictions)

    print(f"\n{'='*60}")
    print("âœ… è¯„ä¼°å®Œæˆ!")
    print(f"   æ¨¡å‹: {model_name}")
    print(f"   å‡†ç¡®ç‡: {accuracy:.4f} ({sum(np.array(predictions) == np.array(labels))}/{len(labels)})")
    print(f"   è€—æ—¶: {end_time - start_time:.2f}ç§’")
    print(f"{'='*60}")

    return accuracy


# --- 6. ä¸»å‡½æ•° ---

def main():
    MODEL_TO_TEST = "DeBERTa-v3-large"  # åœ¨è¿™é‡Œä¿®æ”¹è¦æµ‹è¯•çš„æ¨¡å‹

    model_path = MODEL_PATHS.get(MODEL_TO_TEST)

    if model_path is None:
        print(f"âŒ æœªçŸ¥æ¨¡å‹: {MODEL_TO_TEST}")
        return

    # åˆ¤æ–­æ¨¡å‹ç±»å‹
    if any(x in MODEL_TO_TEST for x in ["DeBERTa", "RoBERTa", "deberta", "roberta"]):
        # Multiple Choiceæ¨¡å‹
        tokenizer, model = load_multiple_choice_model(MODEL_TO_TEST, model_path)
        accuracy = evaluate_multiple_choice_model(
            tokenizer, model, DEV_DATA_PATH, MODEL_TO_TEST
        )
    else:
        # Embeddingæ¨¡å‹
        model = load_embedding_model(MODEL_TO_TEST, model_path)
        accuracy = evaluate_embedding_model(
            model, DEV_DATA_PATH, MODEL_TO_TEST
        )

    # æœ€ç»ˆæ€»ç»“
    print(f"\n{'='*60}")
    print("ğŸ“Š æœ€ç»ˆç»“æœæ€»ç»“")
    print(f"{'='*60}")
    print(f"   æ¨¡å‹: {MODEL_TO_TEST}")
    print(f"   å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"   å¯¹æ¯”:")
    print(f"      E5-large:     67.00%")
    print(f"      Gemini Pro:   71.00%")
    print(f"      å½“å‰æ¨¡å‹:     {accuracy*100:.2f}%")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()