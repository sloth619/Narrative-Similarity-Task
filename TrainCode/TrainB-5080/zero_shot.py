"""
Track B é›¶æ ·æœ¬ (Zero-Shot) è¯„ä¼°è„šæœ¬
- ç›®çš„: åŠ è½½ä¸€ä¸ªæœªç»å¾®è°ƒçš„åŸºç¡€æ¨¡å‹, åœ¨ dev_track_a.jsonl ä¸Šæµ‹è¯•å…¶åŸå§‹æ€§èƒ½ã€‚
- æ”¯æŒ: è‡ªåŠ¨ä¸º Qwen æ¨¡å‹åº”ç”¨ 4-bit é‡åŒ– (ä»¥åŒ¹é…è®­ç»ƒèµ·ç‚¹)ã€‚
"""
import os
import gc
import torch
import time
from sentence_transformers import SentenceTransformer, models
from datasets import load_dataset
from transformers import BitsAndBytesConfig

# æ¸…ç†æ˜¾å­˜
torch.cuda.empty_cache()
gc.collect()

os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# --- 1. é…ç½®åŒº ---

# ğŸ”¥ åœ¨è¿™é‡Œé€‰æ‹©æ‚¨æƒ³æµ‹è¯•çš„æ¨¡å‹
MODEL_TO_TEST = "Qwen3-Embedding-8B"
# MODEL_TO_TEST = "BGE-large-en-v1.5"
# MODEL_TO_TEST = "GTE-large-en-v1.5"
# MODEL_TO_TEST = "Qwen3-Embedding-8B"

# --- 2. è·¯å¾„é…ç½® (æ‚¨çš„ WSL è·¯å¾„) ---
PROJECT_ROOT = "/mnt/e/Code/python/Narrative-Similarity-Task"

MODEL_PATHS = {
    "Qwen3-Embedding-4B": '/mnt/e/model/Qwen3-Embedding-4B',
    "Qwen3-Embedding-8B": '/mnt/e/model/Qwen3-Embedding-8B',
    "BGE-large-en-v1.5": '/mnt/e/model/BGE-large-en-v1.5',
    "GTE-large-en-v1.5": '/mnt/e/model/gte-large-en-v1.5',
}

DEV_DATA_PATH = f'{PROJECT_ROOT}/TrainingSet1/dev_track_a.jsonl'
MODEL_PATH = MODEL_PATHS.get(MODEL_TO_TEST)

if MODEL_PATH is None:
    print(f"âŒ é”™è¯¯: æœªçŸ¥çš„æ¨¡å‹åç§° '{MODEL_TO_TEST}'ã€‚è¯·åœ¨ MODEL_PATHS å­—å…¸ä¸­å®šä¹‰å®ƒã€‚")
    exit()


# --- 3. æ¨¡å‹åŠ è½½ ---

def load_model(model_name, model_path):
    """æ ¹æ®æ¨¡å‹åç§°, åŠ è½½æ ‡å‡†æˆ– 4-bit é‡åŒ–æ¨¡å‹"""
    print(f"\n" + "=" * 60)
    print(f"ğŸ” æ­£åœ¨åŠ è½½é›¶æ ·æœ¬æ¨¡å‹: {model_name}")
    print(f"   è·¯å¾„: {model_path}")
    print("=" * 60)

    start_time = time.time()

    if "Qwen" in model_name:
        print("   æ£€æµ‹åˆ° Qwen æ¨¡å‹ã€‚æ­£åœ¨åº”ç”¨ 4-bit (QLoRA) é…ç½®...")
        bnb_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_quant_type="nf4",
            bnb_4bit_compute_dtype=torch.bfloat16,
            bnb_4bit_use_double_quant=True,
        )

        # ä½¿ç”¨ models.Transformer åŠ è½½ QLoRA é…ç½®
        word_embedding_model = models.Transformer(
            model_path,
            tokenizer_args={'padding_side': 'left'},
            model_args={
                "quantization_config": bnb_config,
                "device_map": "auto",
                "trust_remote_code": True  # Qwen å¿…é¡»
            }
        )

        embedding_dim = word_embedding_model.get_word_embedding_dimension()
        pooling_model = models.Pooling(
            word_embedding_dimension=embedding_dim,
            pooling_mode='lasttoken'  # åŒ¹é…æ‚¨è®­ç»ƒè„šæœ¬çš„æ± åŒ–æ–¹å¼
        )

        model = SentenceTransformer(
            modules=[word_embedding_model, pooling_model],
            device='cuda'
        )
        print(f"   âœ… 4-bit {model_name} åŠ è½½å®Œæˆã€‚")

    else:
        print("   æ£€æµ‹åˆ° BGE/GTEã€‚æ­£åœ¨æ ‡å‡†åŠ è½½...")
        model = SentenceTransformer(model_path, device='cuda')
        print(f"   âœ… {model_name} åŠ è½½å®Œæˆã€‚")

    end_time = time.time()
    print(f"   åŠ è½½è€—æ—¶: {end_time - start_time:.2f} ç§’")
    return model


# --- 4. è¯„ä¼°å‡½æ•° (æ¥è‡ªæ‚¨çš„è„šæœ¬) ---

def evaluate_zero_shot(model, data_path):
    """è¯„ä¼°é›¶æ ·æœ¬æ€§èƒ½"""
    print("\n" + "=" * 60)
    print("ğŸ“Š å¼€å§‹é›¶æ ·æœ¬è¯„ä¼°...")
    print("=" * 60)

    try:
        dev_dataset = load_dataset('json', data_files=data_path, split='train')
    except Exception as e:
        print(f"âŒ åŠ è½½è¯„ä¼°æ–‡ä»¶å¤±è´¥: {data_path}")
        print(f"   é”™è¯¯: {e}")
        return

    correct = 0
    total = 0

    start_time = time.time()
    print(f"å¼€å§‹è¯„ä¼° {len(dev_dataset)} ä¸ªä¸‰å…ƒç»„...")

    for idx, item in enumerate(dev_dataset):
        anchor = item.get('anchor_text') or item.get('anchor_story')
        text_a = item.get('text_a') or item.get('similar_story')
        text_b = item.get('text_b') or item.get('dissimilar_story')
        label_a_closer = item.get('text_a_is_closer')

        if not all([anchor, text_a, text_b]) or label_a_closer is None:
            continue

        # ç¼–ç 
        try:
            embeddings = model.encode(
                [anchor, text_a, text_b],
                show_progress_bar=False,
                batch_size=32  # è¯„ä¼°æ—¶ä½¿ç”¨åˆç†çš„æ‰¹æ¬¡
            )
        except Exception as e:
            print(f"âŒ åœ¨ç¬¬ {idx} é¡¹ç¼–ç æ—¶å‡ºé”™: {e}")
            print(f"   Anchor: {anchor[:50]}...")
            continue

        anchor_emb = embeddings[0]
        text_a_emb = embeddings[1]
        text_b_emb = embeddings[2]

        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        sim_a = torch.nn.functional.cosine_similarity(
            torch.tensor(anchor_emb).unsqueeze(0),
            torch.tensor(text_a_emb).unsqueeze(0)
        ).item()

        sim_b = torch.nn.functional.cosine_similarity(
            torch.tensor(anchor_emb).unsqueeze(0),
            torch.tensor(text_b_emb).unsqueeze(0)
        ).item()

        # é¢„æµ‹
        prediction = sim_a > sim_b

        if prediction == label_a_closer:
            correct += 1
        total += 1

        # è¿›åº¦æç¤º
        if (idx + 1) % 50 == 0:
            print(f"  ...å·²è¯„ä¼°: {idx + 1}/{len(dev_dataset)}, å½“å‰å‡†ç¡®ç‡: {correct / total:.2%}")

    end_time = time.time()
    accuracy = correct / total if total > 0 else 0

    print("\n" + "=" * 60)
    print("âœ… é›¶æ ·æœ¬è¯„ä¼°å®Œæˆ!")
    print(f"   æ¨¡å‹: {MODEL_TO_TEST}")
    print(f"   å‡†ç¡®ç‡: {accuracy:.4f} ({correct}/{total})")
    print(f"   è¯„ä¼°è€—æ—¶: {end_time - start_time:.2f} ç§’")
    print("=" * 60)


# --- 5. æ‰§è¡Œ ---

def main():
    model = load_model(MODEL_TO_TEST, MODEL_PATH)
    evaluate_zero_shot(model, DEV_DATA_PATH)


if __name__ == "__main__":
    main()