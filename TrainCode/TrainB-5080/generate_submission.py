import os
# (ç§»é™¤äº†åœ¨ Windows ä¸Šæ— æ•ˆçš„ PYTORCH_CUDA_ALLOC_CONF)

import json
import zipfile
import numpy as np  # å¯¼å…¥ numpy ç”¨äºä¿å­˜ .npy
from sentence_transformers import SentenceTransformer, models
from datasets import load_dataset
import torch
from transformers import BitsAndBytesConfig
from peft import LoraConfig, TaskType
from tqdm import tqdm

# --- 1. é…ç½®ä½ çš„æäº¤ ---

# â— åŸºç¡€æ¨¡å‹ (ä½ åœ¨ E ç›˜ä¸Šçš„è·¯å¾„)
BASE_MODEL_PATH = 'E:/model/Qwen3-Embedding-4B'

# â— é€‚é…å™¨è·¯å¾„ (ä½ åˆšåˆšè®­ç»ƒå¥½çš„å¢å¼ºç‰ˆæ¨¡å‹)
ADAPTER_PATH = '../../output/track_b_baseline_model_v2_qlora_5080/best_lora_adapter'

# è€ƒé¢˜æ–‡ä»¶ (CodaLab å¼€å‘é›†)
INPUT_DATA_FILE = '../../TrainingSet1/dev_track_b.jsonl'

# è¾“å‡ºç›®å½• (æˆ‘ä»¬ä¼šåœ¨è¿™é‡Œåˆ›å»º track_b.npy å’Œ submission.zip)
OUTPUT_DIR = '../../submissions/augmented_v2_5080_submission'  # (æ–°æ–‡ä»¶å¤¹)

# --- 2. CodaLab è¦æ±‚çš„æ–‡ä»¶å (å·²ä¿®å¤) ---
OUTPUT_NPY_FILE = 'track_b.npy'  # ç›®æ ‡æ–‡ä»¶æ˜¯ .npy
OUTPUT_ZIP_FILE = 'submission.zip'


def main():
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆ CodaLab æäº¤æ–‡ä»¶ (.npy æ ¼å¼)...")
    print(f"   åŸºç¡€æ¨¡å‹: {BASE_MODEL_PATH}")
    print(f"   é€‚é…å™¨ (LoRA): {ADAPTER_PATH}")
    print(f"   è¾“å…¥æ•°æ®: {INPUT_DATA_FILE}")

    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # === 1. åŠ è½½ QLoRA æ¨¡å‹ (å’Œè®­ç»ƒæ—¶ä¸€æ ·) ===
    # æˆ‘ä»¬å¿…é¡»å…ˆåŠ è½½ 4-bit çš„åŸºç¡€æ¨¡å‹ï¼Œç„¶åå†æŠŠ LoRA é€‚é…å™¨â€œæ’â€ä¸Šå»

    print("æ­£åœ¨åŠ è½½ 4-bit åŸºç¡€æ¨¡å‹...")
    bnb_config = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_compute_dtype=torch.bfloat16,
        bnb_4bit_use_double_quant=True,
    )
    word_embedding_model = models.Transformer(
        BASE_MODEL_PATH,
        tokenizer_args={'padding_side': 'left'},
        model_args={
            "quantization_config": bnb_config,
            "device_map": "auto",
        }
    )

    embedding_dim = word_embedding_model.get_word_embedding_dimension()
    pooling_model = models.Pooling(
        word_embedding_dimension=embedding_dim,
        pooling_mode='lasttoken'
    )
    model = SentenceTransformer(
        modules=[word_embedding_model, pooling_model],
        device='cuda'
    )

    # [å…³é”®] åŠ è½½æˆ‘ä»¬è®­ç»ƒå¥½çš„ LoRA é€‚é…å™¨
    print(f"æ­£åœ¨åŠ è½½ LoRA é€‚é…å™¨...")
    model.load_adapter(ADAPTER_PATH)
    print("âœ… QLoRA æ¨¡å‹åŠ è½½æˆåŠŸï¼")

    # === 2. åŠ è½½è€ƒé¢˜æ•°æ® ===
    print(f"æ­£åœ¨åŠ è½½è€ƒé¢˜: {INPUT_DATA_FILE}")
    dataset = load_dataset('json', data_files=INPUT_DATA_FILE, split='train')

    # (é‡è¦!) å¿…é¡»ä¿æŒåŸå§‹é¡ºåºï¼Œä¸èƒ½è¿‡æ»¤
    sentences_to_encode = []
    for item in dataset:
        text = item.get('text')
        if text is None:
            # å¦‚æœ CodaLab çš„è€ƒé¢˜æœ‰ç©ºè¡Œï¼Œæˆ‘ä»¬ä¹Ÿå¿…é¡»ä¸ºå®ƒç”Ÿæˆä¸€ä¸ªâ€œç©ºâ€å‘é‡
            print("è­¦å‘Šï¼šå‘ç°ä¸€ä¸ªç©ºæ–‡æœ¬è¡Œï¼Œå°†ç¼–ç ä¸ºç©ºå­—ç¬¦ä¸²ã€‚")
            sentences_to_encode.append("")
        else:
            sentences_to_encode.append(text)

    print(f"å·²åŠ è½½ {len(sentences_to_encode)} è¡Œå¾…ç¼–ç çš„æ–‡æœ¬ã€‚")

    # === 3. æ‰¹é‡ç”ŸæˆåµŒå…¥å‘é‡ ===
    print("å¼€å§‹æ‰¹é‡ç¼–ç  (æ¨ç†)...")
    # æ¨ç†æ—¶å¯ä»¥ä½¿ç”¨å¤§æ‰¹æ¬¡ï¼Œä½ çš„ 16GB æ˜¾å­˜è¶³å¤Ÿ
    embeddings = model.encode(
        sentences_to_encode,
        batch_size=64,  # æ¨ç†æ—¶ batch_size å¯ä»¥å¤§ä¸€ç‚¹
        show_progress_bar=True,
        convert_to_tensor=False  # ç›´æ¥è½¬ä¸º numpy array
    )
    print(f"âœ… ç¼–ç å®Œæˆï¼Œç”Ÿæˆäº† {embeddings.shape} å½¢çŠ¶çš„ numpy æ•°ç»„ã€‚")

    # === 4. å†™å…¥ track_b.npy ===
    output_npy_path = os.path.join(OUTPUT_DIR, OUTPUT_NPY_FILE)
    print(f"æ­£åœ¨å†™å…¥ {output_npy_path} ...")

    np.save(output_npy_path, embeddings)  # ä½¿ç”¨ np.save

    print(f"âœ… {OUTPUT_NPY_FILE} å†™å…¥æˆåŠŸã€‚")

    # === 5. æ‰“åŒ… .zip æ–‡ä»¶ ===
    output_zip_path = os.path.join(OUTPUT_DIR, OUTPUT_ZIP_FILE)
    print(f"æ­£åœ¨åˆ›å»º {output_zip_path} ...")

    with zipfile.ZipFile(output_zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
        # å…³é”®: arcname=OUTPUT_NPY_FILE ç¡®ä¿æ–‡ä»¶åœ¨ zip çš„æ ¹ç›®å½•
        zf.write(output_npy_path, arcname=OUTPUT_NPY_FILE)

    print(f"ğŸ‰ æäº¤æ–‡ä»¶å·²ç”Ÿæˆï¼")
    print(f"è¯·åœ¨ CodaLab ä¸Šä¼ è¿™ä¸ªæ–‡ä»¶: {output_zip_path}")


if __name__ == "__main__":
    main()