"""
Track Aé¢„æµ‹ - é›†æˆBGEå’ŒQwen3-Embeddingä¸¤ä¸ªæ¨¡å‹
ä½¿ç”¨åŠ æƒå¹³å‡æå‡æ€§èƒ½
"""
import os
import json
import zipfile
from sentence_transformers import SentenceTransformer, models, util
from datasets import load_dataset
from tqdm import tqdm
import torch
from transformers import BitsAndBytesConfig

# --- é…ç½® ---

# â— BGEæ¨¡å‹è·¯å¾„
BGE_MODEL_PATH = '/mnt/e/Code/python/Narrative-Similarity-Task/output/track_b_bge_baseline_5080_wsl/checkpoint-2136'

# â— Qwen3æ¨¡å‹è·¯å¾„
QWEN_BASE_MODEL = '/mnt/e/model/Qwen3-Embedding-4B'
QWEN_ADAPTER_PATH = '/mnt/e/Code/python/Narrative-Similarity-Task/output/track_b_from_synthetic_5080/checkpoint-356'

# è€ƒé¢˜æ–‡ä»¶
INPUT_DATA_FILE = '/mnt/e/Code/python/Narrative-Similarity-Task/TrainingSet1/dev_track_a.jsonl'

# è¾“å‡ºç›®å½•
OUTPUT_DIR = '/mnt/e/Code/python/Narrative-Similarity-Task/submissions/track_a_ensemble_submission'

# CodaLabè¦æ±‚çš„æ–‡ä»¶å
OUTPUT_JSONL_FILE = 'track_a.jsonl'
OUTPUT_ZIP_FILE = 'submission.zip'

# â­ é›†æˆæƒé‡ (å¯ä»¥è°ƒæ•´è¿™ä¸¤ä¸ªå‚æ•°)
BGE_WEIGHT = 0.6
QWEN_WEIGHT = 0.4


def load_bge_model(model_path):
    """åŠ è½½BGEæ¨¡å‹"""
    print("ğŸ”§ åŠ è½½ BGE æ¨¡å‹...")
    try:
        model = SentenceTransformer(model_path)
        print(f"âœ… BGE åŠ è½½æˆåŠŸ (ç»´åº¦: {model.get_sentence_embedding_dimension()})")
        return model
    except Exception as e:
        print(f"âš ï¸  æœ¬åœ°åŠ è½½å¤±è´¥: {e}")
        print("å°è¯•ä»HuggingFaceä¸‹è½½...")
        model = SentenceTransformer('BAAI/bge-large-en-v1.5')
        print("âœ… BGE ä»HFåŠ è½½æˆåŠŸ")
        return model


def load_qwen_model(base_model_path, adapter_path):
    """åŠ è½½Qwen3-Embeddingæ¨¡å‹ (QLoRA)"""
    print("ğŸ”§ åŠ è½½ Qwen3-Embedding æ¨¡å‹...")

    bnb_config = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_compute_dtype=torch.bfloat16,
        bnb_4bit_use_double_quant=True,
    )

    word_embedding_model = models.Transformer(
        base_model_path,
        tokenizer_args={'padding_side': 'left'},
        model_args={
            "quantization_config": bnb_config,
            "device_map": "auto",
        }
    )

    embedding_dim = word_embedding_model.get_word_embedding_dimension()
    pooling_model = models.Pooling(
        word_embedding_dimension=embedding_dim,
        pooling_mode='lasttoken'
    )

    model = SentenceTransformer(
        modules=[word_embedding_model, pooling_model],
        device='cuda'
    )

    model.load_adapter(adapter_path)
    print(f"âœ… Qwen3 åŠ è½½æˆåŠŸ (ç»´åº¦: {embedding_dim})")
    return model


def compute_similarity_scores(bge_model, qwen_model, anchor, text_a, text_b):
    """
    è®¡ç®—é›†æˆç›¸ä¼¼åº¦åˆ†æ•°
    è¿”å›: (sim_a, sim_b) - anchorä¸text_aå’Œtext_bçš„åŠ æƒç›¸ä¼¼åº¦
    """
    # === 1. BGEç›¸ä¼¼åº¦ ===
    bge_embeddings = bge_model.encode(
        [anchor, text_a, text_b],
        convert_to_tensor=True,
        normalize_embeddings=True,
        show_progress_bar=False
    )

    bge_sim_a = util.cos_sim(bge_embeddings[0], bge_embeddings[1]).item()
    bge_sim_b = util.cos_sim(bge_embeddings[0], bge_embeddings[2]).item()

    # === 2. Qwen3ç›¸ä¼¼åº¦ ===
    qwen_embeddings = qwen_model.encode(
        [anchor, text_a, text_b],
        convert_to_tensor=True,
        show_progress_bar=False
    )

    qwen_sim_a = util.cos_sim(qwen_embeddings[0], qwen_embeddings[1]).item()
    qwen_sim_b = util.cos_sim(qwen_embeddings[0], qwen_embeddings[2]).item()

    # === 3. åŠ æƒé›†æˆ ===
    ensemble_sim_a = BGE_WEIGHT * bge_sim_a + QWEN_WEIGHT * qwen_sim_a
    ensemble_sim_b = BGE_WEIGHT * bge_sim_b + QWEN_WEIGHT * qwen_sim_b

    return ensemble_sim_a, ensemble_sim_b


def main():
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆé›†æˆæ¨¡å‹ Track A æäº¤æ–‡ä»¶...")
    print(f"   é›†æˆç­–ç•¥: {BGE_WEIGHT:.1f} Ã— BGE + {QWEN_WEIGHT:.1f} Ã— Qwen3")
    print(f"   è¾“å…¥æ•°æ®: {INPUT_DATA_FILE}")

    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # === 1. åŠ è½½ä¸¤ä¸ªæ¨¡å‹ ===
    bge_model = load_bge_model(BGE_MODEL_PATH)
    qwen_model = load_qwen_model(QWEN_BASE_MODEL, QWEN_ADAPTER_PATH)

    print("\nâœ… ä¸¤ä¸ªæ¨¡å‹åŠ è½½å®Œæˆ!\n")

    # === 2. åŠ è½½è€ƒé¢˜æ•°æ® ===
    print(f"æ­£åœ¨åŠ è½½è€ƒé¢˜: {INPUT_DATA_FILE}")
    dataset = load_dataset('json', data_files=INPUT_DATA_FILE, split='train')
    print(f"å·²åŠ è½½ {len(dataset)} ä¸ªä¸‰å…ƒç»„\n")

    # === 3. æ‰¹é‡é¢„æµ‹ ===
    print("å¼€å§‹é›†æˆé¢„æµ‹...")
    predictions = []

    # ç»Ÿè®¡å•æ¨¡å‹æ­£ç¡®æ•° (ç”¨äºåˆ†æ)
    bge_correct = 0
    qwen_correct = 0
    ensemble_correct = 0

    for item in tqdm(dataset, desc="Ensemble Predicting"):
        anchor = item.get('anchor_text')
        text_a = item.get('text_a')
        text_b = item.get('text_b')
        label = item.get('text_a_is_closer')  # çœŸå®æ ‡ç­¾(å¦‚æœæœ‰)

        if not all([anchor, text_a, text_b]):
            print(f"âš ï¸ è­¦å‘Š: å‘ç°ç¼ºå¤±å­—æ®µçš„æ ·æœ¬")
            predictions.append({
                'anchor_text': anchor or "",
                'text_a': text_a or "",
                'text_b': text_b or "",
                'text_a_is_closer': True
            })
            continue

        # è®¡ç®—é›†æˆç›¸ä¼¼åº¦
        ensemble_sim_a, ensemble_sim_b = compute_similarity_scores(
            bge_model, qwen_model, anchor, text_a, text_b
        )

        # é¢„æµ‹
        pred = ensemble_sim_a > ensemble_sim_b

        predictions.append({
            'anchor_text': anchor,
            'text_a': text_a,
            'text_b': text_b,
            'text_a_is_closer': bool(pred)
        })

    print(f"\nâœ… é¢„æµ‹å®Œæˆï¼Œå…± {len(predictions)} ä¸ªæ ·æœ¬")

    # === 4. å†™å…¥ track_a.jsonl ===
    output_jsonl_path = os.path.join(OUTPUT_DIR, OUTPUT_JSONL_FILE)
    print(f"\næ­£åœ¨å†™å…¥ {output_jsonl_path} ...")

    with open(output_jsonl_path, 'w', encoding='utf-8') as f:
        for pred in predictions:
            f.write(json.dumps(pred, ensure_ascii=False) + '\n')

    print(f"âœ… {OUTPUT_JSONL_FILE} å†™å…¥æˆåŠŸ")

    # === 5. æ‰“åŒ… .zip æ–‡ä»¶ ===
    output_zip_path = os.path.join(OUTPUT_DIR, OUTPUT_ZIP_FILE)
    print(f"\næ­£åœ¨åˆ›å»º {output_zip_path} ...")

    with zipfile.ZipFile(output_zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
        zf.write(output_jsonl_path, arcname=OUTPUT_JSONL_FILE)

    print(f"\nğŸ‰ æäº¤æ–‡ä»¶å·²ç”Ÿæˆï¼")
    print(f"ğŸ“ è¾“å‡ºä½ç½®: {output_zip_path}")
    print(f"è¯·åœ¨ CodaLab ä¸Šä¼ è¿™ä¸ªæ–‡ä»¶")

    # === 6. éªŒè¯é¢„æµ‹åˆ†å¸ƒ ===
    true_count = sum(1 for p in predictions if p['text_a_is_closer'])
    false_count = len(predictions) - true_count

    print(f"\nğŸ“Š é¢„æµ‹åˆ†å¸ƒ:")
    print(f"   text_aæ›´æ¥è¿‘: {true_count} ({true_count / len(predictions) * 100:.1f}%)")
    print(f"   text_bæ›´æ¥è¿‘: {false_count} ({false_count / len(predictions) * 100:.1f}%)")

    # === 7. æ˜¾ç¤ºé…ç½® ===
    print(f"\nâš™ï¸  é›†æˆé…ç½®:")
    print(f"   BGEæƒé‡: {BGE_WEIGHT}")
    print(f"   Qwen3æƒé‡: {QWEN_WEIGHT}")
    print(f"   é¢„æœŸæå‡: 0.66 â†’ 0.67-0.68")


if __name__ == "__main__":
    main()