"""
Track Aæäº¤æ–‡ä»¶ç”Ÿæˆè„šæœ¬
ä½¿ç”¨è®­ç»ƒå¥½çš„Qwen3-Reranker-4Bæ¨¡å‹ç”Ÿæˆpredictions.jsonl
"""
import os
import json
import zipfile
from sentence_transformers import CrossEncoder
from datasets import load_dataset
from tqdm import tqdm
import torch

# --- é…ç½® ---

# â— æ¨¡å‹è·¯å¾„ (è®­ç»ƒå¥½çš„æ¨¡å‹)
MODEL_PATH = '/mnt/e/Code/python/Narrative-Similarity-Task/output/track_a_trainer_4bit/checkpoint-238'

# è€ƒé¢˜æ–‡ä»¶ (CodaLab å¼€å‘é›†)
INPUT_DATA_FILE = '/mnt/e/Code/python/Narrative-Similarity-Task//TrainingSet1/dev_track_a.jsonl'

# è¾“å‡ºç›®å½•
OUTPUT_DIR = '/mnt/e/Code/python/Narrative-Similarity-Task//submissions/track_a_submission'

# CodaLab è¦æ±‚çš„æ–‡ä»¶å
OUTPUT_JSONL_FILE = 'track_a.jsonl'
OUTPUT_ZIP_FILE = 'submission.zip'


def main():
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆ Track A CodaLab æäº¤æ–‡ä»¶...")
    print(f"   æ¨¡å‹è·¯å¾„: {MODEL_PATH}")
    print(f"   è¾“å…¥æ•°æ®: {INPUT_DATA_FILE}")

    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # === 1. åŠ è½½æ¨¡å‹ ===
    print("æ­£åœ¨åŠ è½½ Reranker æ¨¡å‹...")
    model = CrossEncoder(
        MODEL_PATH,
        num_labels=1,
        max_length=512,
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (è®¾å¤‡: {model.device})")

    # === 2. åŠ è½½è€ƒé¢˜æ•°æ® ===
    print(f"æ­£åœ¨åŠ è½½è€ƒé¢˜: {INPUT_DATA_FILE}")
    dataset = load_dataset('json', data_files=INPUT_DATA_FILE, split='train')
    print(f"å·²åŠ è½½ {len(dataset)} ä¸ªä¸‰å…ƒç»„")

    # === 3. æ‰¹é‡é¢„æµ‹ ===
    print("å¼€å§‹é¢„æµ‹...")
    predictions = []

    for item in tqdm(dataset, desc="Predicting"):
        anchor = item.get('anchor_text')
        text_a = item.get('text_a')
        text_b = item.get('text_b')

        if not all([anchor, text_a, text_b]):
            print(f"âš ï¸ è­¦å‘Š: å‘ç°ç¼ºå¤±å­—æ®µçš„æ ·æœ¬,è·³è¿‡")
            # å³ä½¿ç¼ºå¤±,ä¹Ÿè¦æ·»åŠ ä¸€ä¸ªé¢„æµ‹ä»¥ä¿æŒé¡ºåº
            predictions.append({
                'anchor_text': anchor or "",
                'text_a': text_a or "",
                'text_b': text_b or "",
                'text_a_is_closer': True  # é»˜è®¤é¢„æµ‹
            })
            continue

        # è®¡ç®—ä¸¤ä¸ªåˆ†æ•°
        score_a = model.predict([[anchor, text_a]])[0]
        score_b = model.predict([[anchor, text_b]])[0]

        # é¢„æµ‹: text_aåˆ†æ•°æ›´é«˜åˆ™ä¸ºTrue
        pred = score_a > score_b

        predictions.append({
            'anchor_text': anchor,
            'text_a': text_a,
            'text_b': text_b,
            'text_a_is_closer': bool(pred)  # ç¡®ä¿æ˜¯boolç±»å‹
        })

    print(f"âœ… é¢„æµ‹å®Œæˆï¼Œå…± {len(predictions)} ä¸ªæ ·æœ¬")

    # === 4. å†™å…¥ predictions.jsonl ===
    output_jsonl_path = os.path.join(OUTPUT_DIR, OUTPUT_JSONL_FILE)
    print(f"æ­£åœ¨å†™å…¥ {output_jsonl_path} ...")

    with open(output_jsonl_path, 'w', encoding='utf-8') as f:
        for pred in predictions:
            f.write(json.dumps(pred, ensure_ascii=False) + '\n')

    print(f"âœ… {OUTPUT_JSONL_FILE} å†™å…¥æˆåŠŸ")

    # === 5. æ‰“åŒ… .zip æ–‡ä»¶ ===
    output_zip_path = os.path.join(OUTPUT_DIR, OUTPUT_ZIP_FILE)
    print(f"æ­£åœ¨åˆ›å»º {output_zip_path} ...")

    with zipfile.ZipFile(output_zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
        # å…³é”®: arcnameç¡®ä¿æ–‡ä»¶åœ¨zipçš„æ ¹ç›®å½•
        zf.write(output_jsonl_path, arcname=OUTPUT_JSONL_FILE)

    print(f"ğŸ‰ æäº¤æ–‡ä»¶å·²ç”Ÿæˆï¼")
    print(f"ğŸ“ è¾“å‡ºä½ç½®: {output_zip_path}")
    print(f"è¯·åœ¨ CodaLab ä¸Šä¼ è¿™ä¸ªæ–‡ä»¶: {output_zip_path}")

    # === 6. éªŒè¯é¢„æµ‹åˆ†å¸ƒ ===
    true_count = sum(1 for p in predictions if p['text_a_is_closer'])
    false_count = len(predictions) - true_count
    print(f"\nğŸ“Š é¢„æµ‹åˆ†å¸ƒ:")
    print(f"   text_aæ›´æ¥è¿‘: {true_count} ({true_count / len(predictions) * 100:.1f}%)")
    print(f"   text_bæ›´æ¥è¿‘: {false_count} ({false_count / len(predictions) * 100:.1f}%)")


if __name__ == "__main__":
    main()