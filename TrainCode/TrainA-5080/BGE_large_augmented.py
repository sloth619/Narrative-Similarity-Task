"""
Track Aé¢„æµ‹ - ä½¿ç”¨BGE-large-en-v1.5æ¨¡å‹
"""
import os
import json
import zipfile
from sentence_transformers import SentenceTransformer, util
from datasets import load_dataset
from tqdm import tqdm

# --- é…ç½® ---

# â— BGEæ¨¡å‹è·¯å¾„
MODEL_PATH = '/mnt/e/Code/python/Narrative-Similarity-Task/output/track_b_bge_optimized_5080/checkpoint-3840'

# è€ƒé¢˜æ–‡ä»¶ (CodaLab å¼€å‘é›†)
INPUT_DATA_FILE = '/mnt/e/Code/python/Narrative-Similarity-Task/TrainingSet1/dev_track_a.jsonl'

# è¾“å‡ºç›®å½•
OUTPUT_DIR = '/mnt/e/Code/python/Narrative-Similarity-Task/submissions/track_a_bge_submission'

# CodaLabè¦æ±‚çš„æ–‡ä»¶å
OUTPUT_JSONL_FILE = 'track_a.jsonl'
OUTPUT_ZIP_FILE = 'submission.zip'


def main():
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆ BGE Track A æäº¤æ–‡ä»¶...")
    print(f"   æ¨¡å‹è·¯å¾„: {MODEL_PATH}")
    print(f"   è¾“å…¥æ•°æ®: {INPUT_DATA_FILE}")

    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # === 1. åŠ è½½BGEæ¨¡å‹ ===
    print("æ­£åœ¨åŠ è½½ BGE æ¨¡å‹...")
    try:
        model = SentenceTransformer(MODEL_PATH)
        print("âœ… BGE æ¨¡å‹åŠ è½½æˆåŠŸ (ä»æœ¬åœ°checkpoint)")
    except Exception as e:
        print(f"æœ¬åœ°åŠ è½½å¤±è´¥: {e}")
        print("å°è¯•ä»HuggingFaceä¸‹è½½åŸå§‹æ¨¡å‹...")
        model = SentenceTransformer('BAAI/bge-large-en-v1.5')
        print("âœ… BGE æ¨¡å‹ä»HFåŠ è½½æˆåŠŸ")

    print(f"   Embeddingç»´åº¦: {model.get_sentence_embedding_dimension()}")

    # === 2. åŠ è½½è€ƒé¢˜æ•°æ® ===
    print(f"æ­£åœ¨åŠ è½½è€ƒé¢˜: {INPUT_DATA_FILE}")
    dataset = load_dataset('json', data_files=INPUT_DATA_FILE, split='train')
    print(f"å·²åŠ è½½ {len(dataset)} ä¸ªä¸‰å…ƒç»„")

    # === 3. æ‰¹é‡é¢„æµ‹ ===
    print("å¼€å§‹é¢„æµ‹...")
    predictions = []

    for item in tqdm(dataset, desc="Predicting"):
        anchor = item.get('anchor_text')
        text_a = item.get('text_a')
        text_b = item.get('text_b')

        if not all([anchor, text_a, text_b]):
            print(f"âš ï¸ è­¦å‘Š: å‘ç°ç¼ºå¤±å­—æ®µçš„æ ·æœ¬")
            # å³ä½¿ç¼ºå¤±,ä¹Ÿè¦æ·»åŠ ä¸€ä¸ªé¢„æµ‹ä»¥ä¿æŒé¡ºåº
            predictions.append({
                'anchor_text': anchor or "",
                'text_a': text_a or "",
                'text_b': text_b or "",
                'text_a_is_closer': True  # é»˜è®¤é¢„æµ‹
            })
            continue

        # ç¼–ç ä¸‰ä¸ªæ–‡æœ¬
        embeddings = model.encode(
            [anchor, text_a, text_b],
            convert_to_tensor=True,
            normalize_embeddings=True,  # BGEæ¨èå½’ä¸€åŒ–
            show_progress_bar=False
        )

        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        sim_a = util.cos_sim(embeddings[0], embeddings[1]).item()
        sim_b = util.cos_sim(embeddings[0], embeddings[2]).item()

        # é¢„æµ‹: text_aç›¸ä¼¼åº¦æ›´é«˜åˆ™ä¸ºTrue
        pred = sim_a > sim_b

        predictions.append({
            'anchor_text': anchor,
            'text_a': text_a,
            'text_b': text_b,
            'text_a_is_closer': bool(pred)  # ç¡®ä¿æ˜¯boolç±»å‹
        })

    print(f"âœ… é¢„æµ‹å®Œæˆï¼Œå…± {len(predictions)} ä¸ªæ ·æœ¬")

    # === 4. å†™å…¥ track_a.jsonl ===
    output_jsonl_path = os.path.join(OUTPUT_DIR, OUTPUT_JSONL_FILE)
    print(f"æ­£åœ¨å†™å…¥ {output_jsonl_path} ...")

    with open(output_jsonl_path, 'w', encoding='utf-8') as f:
        for pred in predictions:
            f.write(json.dumps(pred, ensure_ascii=False) + '\n')

    print(f"âœ… {OUTPUT_JSONL_FILE} å†™å…¥æˆåŠŸ")

    # === 5. æ‰“åŒ… .zip æ–‡ä»¶ ===
    output_zip_path = os.path.join(OUTPUT_DIR, OUTPUT_ZIP_FILE)
    print(f"æ­£åœ¨åˆ›å»º {output_zip_path} ...")

    with zipfile.ZipFile(output_zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
        zf.write(output_jsonl_path, arcname=OUTPUT_JSONL_FILE)

    print(f"ğŸ‰ æäº¤æ–‡ä»¶å·²ç”Ÿæˆï¼")
    print(f"ğŸ“ è¾“å‡ºä½ç½®: {output_zip_path}")
    print(f"è¯·åœ¨ CodaLab ä¸Šä¼ è¿™ä¸ªæ–‡ä»¶: {output_zip_path}")

    # === 6. éªŒè¯é¢„æµ‹åˆ†å¸ƒ ===
    true_count = sum(1 for p in predictions if p['text_a_is_closer'])
    false_count = len(predictions) - true_count
    print(f"\nğŸ“Š é¢„æµ‹åˆ†å¸ƒ:")
    print(f"   text_aæ›´æ¥è¿‘: {true_count} ({true_count / len(predictions) * 100:.1f}%)")
    print(f"   text_bæ›´æ¥è¿‘: {false_count} ({false_count / len(predictions) * 100:.1f}%)")


if __name__ == "__main__":
    main()